{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f26c1f2-3c58-4b52-a79f-3c2f9170f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC as SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "319f4574-97a2-411e-a8c1-f896f5b23998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"telecom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f79c4-b531-406d-bb8a-80d3fe9f9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['tenure', 'customerID'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a631d93-3686-4470-a651-e3e091175ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\n",
    "    'PhoneService': {'Yes': 1, 'No': 0},\n",
    "    'Partner': {'Yes': 1, 'No': 0},\n",
    "    'gender': {'Female': 1, 'Male': 0},\n",
    "    'Dependents': {'Yes': 1, 'No': 0}, \n",
    "    'MultipleLines': {'Yes': 1, 'No': 0, 'No phone service': 2},\n",
    "    'InternetService': {'DSL': 1, 'Fiber optic':2, 'No':0},\n",
    "    'OnlineSecurity': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'OnlineBackup': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'DeviceProtection': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'TechSupport': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'StreamingTV': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'StreamingMovies': {'Yes': 1, 'No': 0, 'No internet service': 2},\n",
    "    'Contract':{'Month-to-month':1, 'One year': 0, 'Two year':2},\n",
    "    'PaperlessBilling':{'Yes': 1, 'No': 0},\n",
    "    'PaymentMethod':{'Electronic check':1, 'Mailed check':0, 'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3},\n",
    "    'Churn':{'Yes':1, 'No':0}\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e10c5-5bb7-456d-a951-c42002fe6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PhoneService'] = df['PhoneService'].astype(int)\n",
    "df['Partner'] = df['Partner'].astype(int)\n",
    "df['gender'] = df['gender'].astype(int)\n",
    "df['Dependents'] = df['Dependents'].astype(int)\n",
    "df['MultipleLines'] = df['MultipleLines'].astype(int)\n",
    "df['OnlineSecurity'] = df['OnlineSecurity'].astype(int)\n",
    "df['OnlineBackup'] = df['OnlineBackup'].astype(int)\n",
    "df['DeviceProtection'] = df['DeviceProtection'].astype(int)\n",
    "df['TechSupport'] = df['TechSupport'].astype(int)\n",
    "df['StreamingTV'] = df['StreamingTV'].astype(int)\n",
    "df['StreamingMovies'] = df['StreamingMovies'].astype(int)\n",
    "df['Contract'] = df['Contract'].astype(int)\n",
    "df['PaperlessBilling'] = df['PaperlessBilling'].astype(int)\n",
    "df['PaymentMethod'] = df['PaymentMethod'].astype(int)\n",
    "df['Churn'] = df['Churn'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1841b53-cf0c-47c2-b0b1-d2f1e8ff379f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eb6b2-150a-4203-a4d3-87ef9f8d1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02feaa-dbb4-4e84-abc9-88d5b8f49417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "df.fillna(df[\"TotalCharges\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47b337-0116-461e-87d3-f002bdc990f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_col = df.columns[df.columns != 'Churn'].tolist()\n",
    "y_col = 'Churn'\n",
    "X = df[X_col]\n",
    "y = df[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c32f3a-9562-42d6-81bc-5fa8e17c169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 0.81\n",
      "Decision Tree: Accuracy = 0.74\n",
      "Random Forest: Accuracy = 0.80\n",
      "Support Vector Machine: Accuracy = 0.80\n",
      "K-Nearest Neighbors: Accuracy = 0.76\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVM(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "# Display results\n",
    "for name, accuracy in results.items():\n",
    "    print(f'{name}: Accuracy = {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df58dc8-82a7-4ce4-87d7-4905e53a6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Esembling techniques to improve model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa8702a-dc3e-4985-bf0c-25485281e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier Accuracy: 0.8069096071935636\n",
      "GradientBoostingClassifier Accuracy: 0.8026502602934217\n",
      "RandomForestClassifier Accuracy: 0.7946048272598202\n",
      "BaggingClassifier Accuracy: 0.783719829626124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "bagging = BaggingClassifier(n_estimators=100, random_state=42)\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "adaboost_pred = ada.predict(X_test)\n",
    "\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "bagging_pred = bagging.predict(X_test)\n",
    "# Accuracy scores\n",
    "ada_accuracy = accuracy_score(y_test, adaboost_pred)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
    "\n",
    "print(\"AdaBoostClassifier Accuracy:\", ada_accuracy)\n",
    "print(\"GradientBoostingClassifier Accuracy:\", gb_accuracy)\n",
    "print(\"RandomForestClassifier Accuracy:\", rf_accuracy)\n",
    "print(\"BaggingClassifier Accuracy:\", bagging_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d928e3-155a-46b4-8009-34ccc850a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Randomized Hyperparameters: {'max_depth': 10, 'min_samples_split': 13, 'n_estimators': 259}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter distributions\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),  # Random integer between 100 and 500\n",
    "    'max_depth': [None, 10, 20],         # List of possible values\n",
    "    'min_samples_split': randint(2, 20)  # Random integer between 2 and 20\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Perform randomized search\n",
    "randomized_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy')\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_random = randomized_search.best_params_\n",
    "print(f\"Best Randomized Hyperparameters: {best_params_random}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd33e2e-2b42-45f2-86c3-fca144774113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=13, n_estimators=259)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=13, n_estimators=259)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_split=13, n_estimators=259)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_max_depth = 10\n",
    "best_min_samples_split = 13\n",
    "best_n_estimators = 259\n",
    "\n",
    "Last_rf_model = RandomForestClassifier(max_depth=best_max_depth, \n",
    "                                        min_samples_split=best_min_samples_split,\n",
    "                                        n_estimators=best_n_estimators)\n",
    "\n",
    "# Training the last Random Forest model on the entire training dataset\n",
    "Last_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ea8edb2-6d52-4881-ab61-ed77447c027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8021769995267393\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1539\n",
      "           1       0.69      0.50      0.58       574\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.76      0.71      0.72      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1409  130]\n",
      " [ 288  286]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = Last_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ddf1f-f208-45c0-bea3-16bf32fda2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning for Support Vector Machine...\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "        {\n",
    "        'name': 'Support Vector Machine',\n",
    "        'classifier': SVM(),\n",
    "        'param_distributions': {\n",
    "            'C': uniform(loc=0, scale=10),\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'kernel': ['linear', 'rbf', 'poly']\n",
    "        }\n",
    "        }\n",
    "] \n",
    "\n",
    "# Perform hyperparameter tuning for each classifier\n",
    "best_models = {}\n",
    "for classifier in classifiers:\n",
    "    print(f\"Hyperparameter tuning for {classifier['name']}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=classifier['classifier'], \n",
    "                                       param_distributions=classifier['param_distributions'], \n",
    "                                       n_iter=100, \n",
    "                                       cv=5, \n",
    "                                       scoring='accuracy', \n",
    "                                       random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_models[classifier['name']] = {\n",
    "        'best_estimator': random_search.best_estimator_,\n",
    "        'best_params': random_search.best_params_,\n",
    "        'best_score': random_search.best_score_\n",
    "    }\n",
    "    print(f\"Best Score: {best_models[classifier['name']]['best_score']}\")\n",
    "    print(f\"Best Parameters: {best_models[classifier['name']]['best_params']}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "print(\"Test Set Evaluation:\")\n",
    "for name, model_info in best_models.items():\n",
    "    best_model = model_info['best_estimator']\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} - Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1248c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for LogisticRegression:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COMFORT\\anaconda3\\envs\\Pandas\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\COMFORT\\anaconda3\\envs\\Pandas\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\COMFORT\\anaconda3\\envs\\Pandas\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\COMFORT\\anaconda3\\envs\\Pandas\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\COMFORT\\anaconda3\\envs\\Pandas\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores:\n",
      "Fold 1: 0.801277501774308\n",
      "Fold 2: 0.8055358410220014\n",
      "Fold 3: 0.7877927608232789\n",
      "Fold 4: 0.78125\n",
      "Fold 5: 0.7876420454545454\n",
      "\n",
      "Average Cross-Validation Score: 0.7927\n",
      "\n",
      "Cross-validation for SVC:\n",
      "Cross-Validation Scores:\n",
      "Fold 1: 0.7352732434350603\n",
      "Fold 2: 0.7331440738112136\n",
      "Fold 3: 0.7246273953158269\n",
      "Fold 4: 0.7329545454545454\n",
      "Fold 5: 0.7471590909090909\n",
      "\n",
      "Average Cross-Validation Score: 0.7346\n",
      "\n",
      "Cross-validation for RandomForestClassifier:\n",
      "Cross-Validation Scores:\n",
      "Fold 1: 0.7913413768630234\n",
      "Fold 2: 0.8026969481902059\n",
      "Fold 3: 0.7799858055358411\n",
      "Fold 4: 0.7840909090909091\n",
      "Fold 5: 0.7883522727272727\n",
      "\n",
      "Average Cross-Validation Score: 0.7893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def perform_cross_validation(model, X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    for fold, score in enumerate(cv_scores, start=1):\n",
    "        print(f\"Fold {fold}: {score}\")\n",
    "    \n",
    "    avg_cv_score = cv_scores.mean()\n",
    "    print(f\"\\nAverage Cross-Validation Score: {avg_cv_score:.4f}\")\n",
    "\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    SVM(),\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "for model in models:\n",
    "    print(f\"Cross-validation for {model.__class__.__name__}:\")\n",
    "    perform_cross_validation(model, X, y)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13aa5db-f891-427f-9500-6f2ca8088e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
