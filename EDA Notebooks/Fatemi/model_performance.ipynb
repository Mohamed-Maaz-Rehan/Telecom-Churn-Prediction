{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171ba6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e045f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Telecom Churn Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c30963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"customerID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbd424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping dictionary\n",
    "\n",
    "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
    "df['MultipleLines'] = df['MultipleLines'].map({'No': 0, 'Yes': 1, 'No phone service': 2})\n",
    "df['Contract'] = df['Contract'].map({'Month-to-month': 0, 'One year': 1, 'Two year': 2})\n",
    "df['InternetService'] = df['InternetService'].map({'No': 0, 'DSL': 1, 'Fiber optic': 2})\n",
    "df['PaymentMethod'] = df['PaymentMethod'].map({'Electronic check': 0, 'Mailed check': 1, 'Bank transfer (automatic)': 2, 'Credit card (automatic)': 3})\n",
    "df['TotalCharges']=df['TotalCharges'].replace({' ': 0})\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
    "\n",
    "for col in ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']:\n",
    "    df[col] = df[col].map({'No': 0, 'Yes': 1})\n",
    "for col in ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']:\n",
    "    df[col] = df[col].map({'No': 0, 'Yes': 1, 'No internet service': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b54f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717cf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using min max scaler technique on tenure, monthlycharges and total charges column\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['tenure', 'MonthlyCharges', 'TotalCharges']] = scaler.fit_transform(df[['tenure', 'MonthlyCharges', 'TotalCharges']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5ff305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7650b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "\n",
    "X = df.drop(\"Churn\", axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9831c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    1560\n",
       "1     552\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3246aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing oversampling as the target column has not equal values\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4197629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_oversampled: (3120, 19)\n",
      "Shape of y_oversampled: (3120,)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_oversampled, y_oversampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Shape of X_oversampled:\", X_oversampled.shape)\n",
    "print(\"Shape of y_oversampled:\", y_oversampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88675341",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98c99ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a18fb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_obj = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e0dc045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3178,  436],\n",
       "       [ 579,  738]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "logistic_obj.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "predict = logistic_obj.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "logistic_confusion_matrix = confusion_matrix(y_test, predict)\n",
    "logistic_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb873075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 81.49%\n",
      "Train precision: 66.67%\n",
      "Train recall: 58.33%\n",
      "Train f1 score: 62.22%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of train data\n",
    "train_predictions = logistic_obj.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Train precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Train recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Train f1 score: {train_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65a73126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 79.42%\n",
      "Test precision: 62.86%\n",
      "Test recall: 56.04%\n",
      "Test f1 score: 59.25%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of test data\n",
    "test_predictions = logistic_obj.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test f1 score: {test_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f50d3",
   "metadata": {},
   "source": [
    "# Descision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bd3ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75abb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree model\n",
    "descision_obj = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c5221f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3178,  436],\n",
       "       [ 579,  738]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "descision_obj.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = descision_obj.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "descision_tree_matrix = confusion_matrix(y_test, predict)\n",
    "descision_tree_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "820a086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.86%\n",
      "Train precision: 100.00%\n",
      "Train recall: 99.46%\n",
      "Train f1 score: 99.73%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of train data\n",
    "train_predictions = descision_obj.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Train precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Train recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Train f1 score: {train_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "22ade0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 71.41%\n",
      "Test precision: 46.64%\n",
      "Test recall: 48.97%\n",
      "Test f1 score: 47.78%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of test data\n",
    "test_predictions = descision_obj.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test f1 score: {test_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fec8f",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58e8e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "14951cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)  # 200 trees in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63f70a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3178,  436],\n",
       "       [ 579,  738]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_clf.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "rf_clf_matrix = confusion_matrix(y_test, predict)\n",
    "rf_clf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac14da6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.86%\n",
      "Train precision: 100.00%\n",
      "Train recall: 99.46%\n",
      "Train f1 score: 99.73%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of train data\n",
    "train_predictions = rf_clf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Train precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Train recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Train f1 score: {train_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c7382f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 78.18%\n",
      "Test precision: 61.04%\n",
      "Test recall: 50.57%\n",
      "Test f1 score: 55.32%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of test data\n",
    "test_predictions = rf_clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test f1 score: {test_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "646e7f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2d2e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d9bea1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3178,  436],\n",
       "       [ 579,  738]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "svm_matrix = confusion_matrix(y_test, predict)\n",
    "svm_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5936c4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 82.62%\n",
      "Train precision: 71.36%\n",
      "Train recall: 55.98%\n",
      "Train f1 score: 62.74%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of train data\n",
    "train_predictions = svm_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Train precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Train recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Train f1 score: {train_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3df6c91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 78.81%\n",
      "Test precision: 62.78%\n",
      "Test recall: 50.72%\n",
      "Test f1 score: 56.11%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of test data\n",
    "test_predictions = svm_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test f1 score: {test_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102cd6a",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c8820e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a8ef513",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2477f4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3178,  436],\n",
       "       [ 579,  738]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "knn_matrix = confusion_matrix(y_test, predict)\n",
    "knn_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ee0f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 83.95%\n",
      "Train precision: 70.21%\n",
      "Train recall: 67.03%\n",
      "Train f1 score: 68.58%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of train data\n",
    "train_predictions = knn.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Train precision: {train_precision * 100:.2f}%\")\n",
    "print(f\"Train recall: {train_recall * 100:.2f}%\")\n",
    "print(f\"Train f1 score: {train_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4f52553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 74.57%\n",
      "Test precision: 52.43%\n",
      "Test recall: 51.56%\n",
      "Test f1 score: 51.99%\n"
     ]
    }
   ],
   "source": [
    "# Fetching the accuracy, precision, recall and f1 of test data\n",
    "test_predictions = knn.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test precision: {test_precision * 100:.2f}%\")\n",
    "print(f\"Test recall: {test_recall * 100:.2f}%\")\n",
    "print(f\"Test f1 score: {test_f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db7ba0c",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ce06a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11d7355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.91%\n"
     ]
    }
   ],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "predictions = gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c99853",
   "metadata": {},
   "source": [
    "# Ada Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d8e44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "461c5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.25%\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ada_boost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ada_boost.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53161224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
